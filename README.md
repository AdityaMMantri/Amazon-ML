# Amazon-ML

![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20Linux-lightgrey)
![Status](https://img.shields.io/badge/status-active-success)


A structured machine learning repository for **feature-based and image-based predictive modeling** using Amazon product data.
The project emphasizes **clean feature engineering, reproducibility, and modular design** suitable for academic evaluation and extension.

---

## Project Overview

This project builds an ML pipeline that combines:

* **Text-based feature engineering**
* **Brand-level target encoding**
* **Numerical normalization**
* **Optional image-based learning**
* **Consistent evaluation using SMAPE**

The repository is structured to clearly separate:

* feature construction
* preprocessing artifacts
* image pipelines
* metrics
* orchestration logic

This separation makes the project **defensible in faculty reviews** and **easy to extend**.

---

## ğŸ“‚ Repository Structure

```
Amazon-ML/
â”œâ”€â”€ Dataset/                       # Dataset CSV files (tracked)
â”‚   â”œâ”€â”€ train_final_features.csv
â”‚   â”œâ”€â”€ test_final_features.csv
â”‚   â””â”€â”€ sample_test_out.csv
â”‚
â”œâ”€â”€ features/                      # Feature engineering & encoding
â”‚   â”œâ”€â”€ binary_features.py
â”‚   â”œâ”€â”€ brand_features.py
â”‚   â”œâ”€â”€ log_quantity.py
â”‚   â”œâ”€â”€ train_brand_expected_price.py
â”‚   â””â”€â”€ test_brand_expected_price.py
â”‚
â”œâ”€â”€ images/                        # Image-based pipelines
â”‚   â”œâ”€â”€ train_images.py
â”‚   â””â”€â”€ test_images.py
â”‚
â”œâ”€â”€ preprocessing/                 # Preprocessing artifacts
â”‚   â””â”€â”€ trained_scaler.py
â”‚
â”œâ”€â”€ metrics/                       # Evaluation metrics
â”‚   â””â”€â”€ smap.py
â”‚
â”œâ”€â”€ train.py                       # Training orchestrator
â”œâ”€â”€ test.py                        # Testing orchestrator
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§  Feature Engineering Pipeline

### Implemented Features

* **Brand extraction** from catalog text
* **Binary indicators**

  * brand present
  * bulk purchase detection
* **Log-normalized quantity** from value/unit parsing
* **Brand expected price encoding**

  * Smoothed target encoding using global mean

These features are designed to capture **semantic, statistical, and behavioral signals** beyond raw text.

---

## ğŸ–¼ï¸ Image Pipeline

Image processing is handled separately to avoid mixing modalities.

* `train_images.py` â†’ image feature learning / training
* `test_images.py` â†’ inference or evaluation on image data

This separation allows:

* independent experimentation
* multimodal extensions later

---

## ğŸ“ Preprocessing & Artifacts

* `trained_scaler.py` reconstructs and saves a **StandardScaler**
* The scaler is fit **only on training data**
* Ensures **trainâ€“test consistency**

---

## ğŸ“Š Evaluation Metric

### SMAPE (Symmetric Mean Absolute Percentage Error)

Used for robust evaluation when prices vary across scales.

Implemented in:

```
metrics/smap.py
```

---

## ğŸ” Training & Testing Flow

### High-Level Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Raw Dataset CSV  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        Feature Engineering     â”‚
          â”‚  (brand, binary, quantity, etc)â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Brand Price Encodingâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Scaling / Normalize â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Model Training/Test â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        Evaluation     â”‚
              â”‚        (SMAPE)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Train the model

```bash
python train.py
```

This script:

* builds features
* applies scaling
* runs the training workflow

---

### 3ï¸âƒ£ Test / Evaluate

```bash
python test.py
```

This script:

* applies learned encodings and scaler
* evaluates predictions using SMAPE

---

## ğŸ§© Import Conventions

When extending the project, follow these imports:

```python
from features.binary_features import ...
from features.brand_features import ...
from features.log_quantity import ...
from preprocessing.trained_scaler import ...
from metrics.smap import smape
from images.train_images import ...
```

**Always run scripts from the repository root.**

---

## ğŸ“Œ Notes & Design Decisions

* Dataset CSV files are **intentionally tracked** for reproducibility
* Other CSVs outside `Dataset/` are ignored to prevent clutter
* Absolute paths should be avoided in future refactors
* Feature scripts currently operate as standalone modules (by design)

----

